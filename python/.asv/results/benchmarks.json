{
    "basic_functions.BasicFunctions.peakmem_read": {
        "code": "class BasicFunctions:\n    def peakmem_read(self, rows, num_symbols):\n        lib = self.ac[get_prewritten_lib_name(rows)]\n        [lib.read(f\"{sym}_sym\").data for sym in range(num_symbols)]\n\n    def setup(self, rows, num_symbols):\n        self.ac = Arctic(\"lmdb://basic_functions\")\n        self.read_reqs = [ReadRequest(f\"{sym}_sym\") for sym in range(num_symbols)]\n    \n        self.df = generate_pseudo_random_dataframe(rows)\n        self.df_short_wide = generate_random_floats_dataframe(5_000, 30_000)\n\n    def setup_cache(self):\n        self.ac = Arctic(\"lmdb://basic_functions\")\n        num_rows, num_symbols = BasicFunctions.params\n    \n        self.dfs = {rows: generate_pseudo_random_dataframe(rows) for rows in num_rows}\n        for rows in num_rows:\n            lib = get_prewritten_lib_name(rows)\n            self.ac.delete_library(lib)\n            self.ac.create_library(lib)\n            lib = self.ac[lib]\n            for sym in range(num_symbols[-1]):\n                lib.write(f\"{sym}_sym\", self.dfs[rows])\n        for sym in range(num_symbols[-1]):\n            lib.write(f\"{sym}_short_wide_sym\", generate_random_floats_dataframe(5_000, 30_000))",
        "name": "basic_functions.BasicFunctions.peakmem_read",
        "param_names": [
            "rows",
            "num_symbols"
        ],
        "params": [
            [
                "100000",
                "150000"
            ],
            [
                "500",
                "1000"
            ]
        ],
        "setup_cache_key": "basic_functions:22",
        "timeout": 6000,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "99011caea3c683c79acd547b5e276526d539fb30b056626bb6e06b8b097e1401"
    },
    "basic_functions.BasicFunctions.peakmem_read_batch": {
        "code": "class BasicFunctions:\n    def peakmem_read_batch(self, rows, num_symbols):\n        lib = self.ac[get_prewritten_lib_name(rows)]\n        read_reqs = [ReadRequest(f\"{sym}_sym\") for sym in range(num_symbols)]\n        lib.read_batch(read_reqs)\n\n    def setup(self, rows, num_symbols):\n        self.ac = Arctic(\"lmdb://basic_functions\")\n        self.read_reqs = [ReadRequest(f\"{sym}_sym\") for sym in range(num_symbols)]\n    \n        self.df = generate_pseudo_random_dataframe(rows)\n        self.df_short_wide = generate_random_floats_dataframe(5_000, 30_000)\n\n    def setup_cache(self):\n        self.ac = Arctic(\"lmdb://basic_functions\")\n        num_rows, num_symbols = BasicFunctions.params\n    \n        self.dfs = {rows: generate_pseudo_random_dataframe(rows) for rows in num_rows}\n        for rows in num_rows:\n            lib = get_prewritten_lib_name(rows)\n            self.ac.delete_library(lib)\n            self.ac.create_library(lib)\n            lib = self.ac[lib]\n            for sym in range(num_symbols[-1]):\n                lib.write(f\"{sym}_sym\", self.dfs[rows])\n        for sym in range(num_symbols[-1]):\n            lib.write(f\"{sym}_short_wide_sym\", generate_random_floats_dataframe(5_000, 30_000))",
        "name": "basic_functions.BasicFunctions.peakmem_read_batch",
        "param_names": [
            "rows",
            "num_symbols"
        ],
        "params": [
            [
                "100000",
                "150000"
            ],
            [
                "500",
                "1000"
            ]
        ],
        "setup_cache_key": "basic_functions:22",
        "timeout": 6000,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "4c85d4771f49f2576d5fcebeb14b0b29344f8eeed291cd9dd2424bfd1311fc34"
    },
    "basic_functions.BasicFunctions.peakmem_read_batch_with_columns": {
        "code": "class BasicFunctions:\n    def peakmem_read_batch_with_columns(self, rows, num_symbols):\n        lib = self.ac[get_prewritten_lib_name(rows)]\n        COLS = [\"value\"]\n        read_reqs = [ReadRequest(f\"{sym}_sym\", columns=COLS) for sym in range(num_symbols)]\n        lib.read_batch(read_reqs)\n\n    def setup(self, rows, num_symbols):\n        self.ac = Arctic(\"lmdb://basic_functions\")\n        self.read_reqs = [ReadRequest(f\"{sym}_sym\") for sym in range(num_symbols)]\n    \n        self.df = generate_pseudo_random_dataframe(rows)\n        self.df_short_wide = generate_random_floats_dataframe(5_000, 30_000)\n\n    def setup_cache(self):\n        self.ac = Arctic(\"lmdb://basic_functions\")\n        num_rows, num_symbols = BasicFunctions.params\n    \n        self.dfs = {rows: generate_pseudo_random_dataframe(rows) for rows in num_rows}\n        for rows in num_rows:\n            lib = get_prewritten_lib_name(rows)\n            self.ac.delete_library(lib)\n            self.ac.create_library(lib)\n            lib = self.ac[lib]\n            for sym in range(num_symbols[-1]):\n                lib.write(f\"{sym}_sym\", self.dfs[rows])\n        for sym in range(num_symbols[-1]):\n            lib.write(f\"{sym}_short_wide_sym\", generate_random_floats_dataframe(5_000, 30_000))",
        "name": "basic_functions.BasicFunctions.peakmem_read_batch_with_columns",
        "param_names": [
            "rows",
            "num_symbols"
        ],
        "params": [
            [
                "100000",
                "150000"
            ],
            [
                "500",
                "1000"
            ]
        ],
        "setup_cache_key": "basic_functions:22",
        "timeout": 6000,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "d0324eb18cf182677fce9bfa5faadc22567bb681ee17ca5c37ec9b9146e7eb72"
    },
    "basic_functions.BasicFunctions.peakmem_read_batch_with_date_ranges": {
        "code": "class BasicFunctions:\n    def peakmem_read_batch_with_date_ranges(self, rows, num_symbols):\n        lib = self.ac[get_prewritten_lib_name(rows)]\n        dr = pd.date_range(\"2023-01-01\", \"2023-01-01\")\n        read_reqs = [ReadRequest(f\"{sym}_sym\", date_range=dr) for sym in range(num_symbols)]\n        lib.read_batch(read_reqs)\n\n    def setup(self, rows, num_symbols):\n        self.ac = Arctic(\"lmdb://basic_functions\")\n        self.read_reqs = [ReadRequest(f\"{sym}_sym\") for sym in range(num_symbols)]\n    \n        self.df = generate_pseudo_random_dataframe(rows)\n        self.df_short_wide = generate_random_floats_dataframe(5_000, 30_000)\n\n    def setup_cache(self):\n        self.ac = Arctic(\"lmdb://basic_functions\")\n        num_rows, num_symbols = BasicFunctions.params\n    \n        self.dfs = {rows: generate_pseudo_random_dataframe(rows) for rows in num_rows}\n        for rows in num_rows:\n            lib = get_prewritten_lib_name(rows)\n            self.ac.delete_library(lib)\n            self.ac.create_library(lib)\n            lib = self.ac[lib]\n            for sym in range(num_symbols[-1]):\n                lib.write(f\"{sym}_sym\", self.dfs[rows])\n        for sym in range(num_symbols[-1]):\n            lib.write(f\"{sym}_short_wide_sym\", generate_random_floats_dataframe(5_000, 30_000))",
        "name": "basic_functions.BasicFunctions.peakmem_read_batch_with_date_ranges",
        "param_names": [
            "rows",
            "num_symbols"
        ],
        "params": [
            [
                "100000",
                "150000"
            ],
            [
                "500",
                "1000"
            ]
        ],
        "setup_cache_key": "basic_functions:22",
        "timeout": 6000,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "1f303cd37f19e018842981cb59d86ab10d543d17039ed12a31549b1f6c232e6b"
    },
    "basic_functions.BasicFunctions.peakmem_read_short_wide": {
        "code": "class BasicFunctions:\n    def peakmem_read_short_wide(self, rows, num_symbols):\n        lib = self.ac[get_prewritten_lib_name(rows)]\n        [lib.read(f\"{sym}_short_wide_sym\").data for sym in range(num_symbols)]\n\n    def setup(self, rows, num_symbols):\n        self.ac = Arctic(\"lmdb://basic_functions\")\n        self.read_reqs = [ReadRequest(f\"{sym}_sym\") for sym in range(num_symbols)]\n    \n        self.df = generate_pseudo_random_dataframe(rows)\n        self.df_short_wide = generate_random_floats_dataframe(5_000, 30_000)\n\n    def setup_cache(self):\n        self.ac = Arctic(\"lmdb://basic_functions\")\n        num_rows, num_symbols = BasicFunctions.params\n    \n        self.dfs = {rows: generate_pseudo_random_dataframe(rows) for rows in num_rows}\n        for rows in num_rows:\n            lib = get_prewritten_lib_name(rows)\n            self.ac.delete_library(lib)\n            self.ac.create_library(lib)\n            lib = self.ac[lib]\n            for sym in range(num_symbols[-1]):\n                lib.write(f\"{sym}_sym\", self.dfs[rows])\n        for sym in range(num_symbols[-1]):\n            lib.write(f\"{sym}_short_wide_sym\", generate_random_floats_dataframe(5_000, 30_000))",
        "name": "basic_functions.BasicFunctions.peakmem_read_short_wide",
        "param_names": [
            "rows",
            "num_symbols"
        ],
        "params": [
            [
                "100000",
                "150000"
            ],
            [
                "500",
                "1000"
            ]
        ],
        "setup_cache_key": "basic_functions:22",
        "timeout": 6000,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "d5b00adabe54306556284c7fa1a3dde90aa841faa8e857f365b7ab951945e126"
    },
    "basic_functions.BasicFunctions.peakmem_read_with_columns": {
        "code": "class BasicFunctions:\n    def peakmem_read_with_columns(self, rows, num_symbols):\n        lib = self.ac[get_prewritten_lib_name(rows)]\n        COLS = [\"value\"]\n        [lib.read(f\"{sym}_sym\", columns=COLS).data for sym in range(num_symbols)]\n\n    def setup(self, rows, num_symbols):\n        self.ac = Arctic(\"lmdb://basic_functions\")\n        self.read_reqs = [ReadRequest(f\"{sym}_sym\") for sym in range(num_symbols)]\n    \n        self.df = generate_pseudo_random_dataframe(rows)\n        self.df_short_wide = generate_random_floats_dataframe(5_000, 30_000)\n\n    def setup_cache(self):\n        self.ac = Arctic(\"lmdb://basic_functions\")\n        num_rows, num_symbols = BasicFunctions.params\n    \n        self.dfs = {rows: generate_pseudo_random_dataframe(rows) for rows in num_rows}\n        for rows in num_rows:\n            lib = get_prewritten_lib_name(rows)\n            self.ac.delete_library(lib)\n            self.ac.create_library(lib)\n            lib = self.ac[lib]\n            for sym in range(num_symbols[-1]):\n                lib.write(f\"{sym}_sym\", self.dfs[rows])\n        for sym in range(num_symbols[-1]):\n            lib.write(f\"{sym}_short_wide_sym\", generate_random_floats_dataframe(5_000, 30_000))",
        "name": "basic_functions.BasicFunctions.peakmem_read_with_columns",
        "param_names": [
            "rows",
            "num_symbols"
        ],
        "params": [
            [
                "100000",
                "150000"
            ],
            [
                "500",
                "1000"
            ]
        ],
        "setup_cache_key": "basic_functions:22",
        "timeout": 6000,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "b5e64ac4d6b1e6a8b30d80da254907223c3674da86234cc40336752e4cf172d1"
    },
    "basic_functions.BasicFunctions.peakmem_read_with_date_ranges": {
        "code": "class BasicFunctions:\n    def peakmem_read_with_date_ranges(self, rows, num_symbols):\n        lib = self.ac[get_prewritten_lib_name(rows)]\n        dr = pd.date_range(\"2023-01-01\", \"2023-01-01\")\n        [lib.read(f\"{sym}_sym\", date_range=dr).data for sym in range(num_symbols)]\n\n    def setup(self, rows, num_symbols):\n        self.ac = Arctic(\"lmdb://basic_functions\")\n        self.read_reqs = [ReadRequest(f\"{sym}_sym\") for sym in range(num_symbols)]\n    \n        self.df = generate_pseudo_random_dataframe(rows)\n        self.df_short_wide = generate_random_floats_dataframe(5_000, 30_000)\n\n    def setup_cache(self):\n        self.ac = Arctic(\"lmdb://basic_functions\")\n        num_rows, num_symbols = BasicFunctions.params\n    \n        self.dfs = {rows: generate_pseudo_random_dataframe(rows) for rows in num_rows}\n        for rows in num_rows:\n            lib = get_prewritten_lib_name(rows)\n            self.ac.delete_library(lib)\n            self.ac.create_library(lib)\n            lib = self.ac[lib]\n            for sym in range(num_symbols[-1]):\n                lib.write(f\"{sym}_sym\", self.dfs[rows])\n        for sym in range(num_symbols[-1]):\n            lib.write(f\"{sym}_short_wide_sym\", generate_random_floats_dataframe(5_000, 30_000))",
        "name": "basic_functions.BasicFunctions.peakmem_read_with_date_ranges",
        "param_names": [
            "rows",
            "num_symbols"
        ],
        "params": [
            [
                "100000",
                "150000"
            ],
            [
                "500",
                "1000"
            ]
        ],
        "setup_cache_key": "basic_functions:22",
        "timeout": 6000,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "07abccc3a7ed7756b2dc136243134f7b4abe9fe9ebeb05594799433d013763fa"
    },
    "basic_functions.BasicFunctions.peakmem_write": {
        "code": "class BasicFunctions:\n    def peakmem_write(self, rows, num_symbols):\n        lib = self.get_fresh_lib()\n        for sym in range(num_symbols):\n            lib.write(f\"{sym}_sym\", self.df)\n\n    def setup(self, rows, num_symbols):\n        self.ac = Arctic(\"lmdb://basic_functions\")\n        self.read_reqs = [ReadRequest(f\"{sym}_sym\") for sym in range(num_symbols)]\n    \n        self.df = generate_pseudo_random_dataframe(rows)\n        self.df_short_wide = generate_random_floats_dataframe(5_000, 30_000)\n\n    def setup_cache(self):\n        self.ac = Arctic(\"lmdb://basic_functions\")\n        num_rows, num_symbols = BasicFunctions.params\n    \n        self.dfs = {rows: generate_pseudo_random_dataframe(rows) for rows in num_rows}\n        for rows in num_rows:\n            lib = get_prewritten_lib_name(rows)\n            self.ac.delete_library(lib)\n            self.ac.create_library(lib)\n            lib = self.ac[lib]\n            for sym in range(num_symbols[-1]):\n                lib.write(f\"{sym}_sym\", self.dfs[rows])\n        for sym in range(num_symbols[-1]):\n            lib.write(f\"{sym}_short_wide_sym\", generate_random_floats_dataframe(5_000, 30_000))",
        "name": "basic_functions.BasicFunctions.peakmem_write",
        "param_names": [
            "rows",
            "num_symbols"
        ],
        "params": [
            [
                "100000",
                "150000"
            ],
            [
                "500",
                "1000"
            ]
        ],
        "setup_cache_key": "basic_functions:22",
        "timeout": 6000,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "104fe2764eafb20f001dddaff972cd3878c7c7e5ec4425bfa8006eacb8b4a0d8"
    },
    "basic_functions.BasicFunctions.peakmem_write_batch": {
        "code": "class BasicFunctions:\n    def peakmem_write_batch(self, rows, num_symbols):\n        lib = self.get_fresh_lib()\n        df = self.df\n        payloads = [WritePayload(f\"{sym}_sym\", df) for sym in range(num_symbols)]\n        lib.write_batch(payloads)\n\n    def setup(self, rows, num_symbols):\n        self.ac = Arctic(\"lmdb://basic_functions\")\n        self.read_reqs = [ReadRequest(f\"{sym}_sym\") for sym in range(num_symbols)]\n    \n        self.df = generate_pseudo_random_dataframe(rows)\n        self.df_short_wide = generate_random_floats_dataframe(5_000, 30_000)\n\n    def setup_cache(self):\n        self.ac = Arctic(\"lmdb://basic_functions\")\n        num_rows, num_symbols = BasicFunctions.params\n    \n        self.dfs = {rows: generate_pseudo_random_dataframe(rows) for rows in num_rows}\n        for rows in num_rows:\n            lib = get_prewritten_lib_name(rows)\n            self.ac.delete_library(lib)\n            self.ac.create_library(lib)\n            lib = self.ac[lib]\n            for sym in range(num_symbols[-1]):\n                lib.write(f\"{sym}_sym\", self.dfs[rows])\n        for sym in range(num_symbols[-1]):\n            lib.write(f\"{sym}_short_wide_sym\", generate_random_floats_dataframe(5_000, 30_000))",
        "name": "basic_functions.BasicFunctions.peakmem_write_batch",
        "param_names": [
            "rows",
            "num_symbols"
        ],
        "params": [
            [
                "100000",
                "150000"
            ],
            [
                "500",
                "1000"
            ]
        ],
        "setup_cache_key": "basic_functions:22",
        "timeout": 6000,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "7f1197d0534d206e552a90bce2418d5e1b02e13dbb371bd95281c60273834361"
    },
    "basic_functions.BasicFunctions.peakmem_write_short_wide": {
        "code": "class BasicFunctions:\n    def peakmem_write_short_wide(self, rows, num_symbols):\n        lib = self.get_fresh_lib()\n        for sym in range(num_symbols):\n            lib.write(f\"{sym}_short_wide_sym\", self.df_short_wide)\n\n    def setup(self, rows, num_symbols):\n        self.ac = Arctic(\"lmdb://basic_functions\")\n        self.read_reqs = [ReadRequest(f\"{sym}_sym\") for sym in range(num_symbols)]\n    \n        self.df = generate_pseudo_random_dataframe(rows)\n        self.df_short_wide = generate_random_floats_dataframe(5_000, 30_000)\n\n    def setup_cache(self):\n        self.ac = Arctic(\"lmdb://basic_functions\")\n        num_rows, num_symbols = BasicFunctions.params\n    \n        self.dfs = {rows: generate_pseudo_random_dataframe(rows) for rows in num_rows}\n        for rows in num_rows:\n            lib = get_prewritten_lib_name(rows)\n            self.ac.delete_library(lib)\n            self.ac.create_library(lib)\n            lib = self.ac[lib]\n            for sym in range(num_symbols[-1]):\n                lib.write(f\"{sym}_sym\", self.dfs[rows])\n        for sym in range(num_symbols[-1]):\n            lib.write(f\"{sym}_short_wide_sym\", generate_random_floats_dataframe(5_000, 30_000))",
        "name": "basic_functions.BasicFunctions.peakmem_write_short_wide",
        "param_names": [
            "rows",
            "num_symbols"
        ],
        "params": [
            [
                "100000",
                "150000"
            ],
            [
                "500",
                "1000"
            ]
        ],
        "setup_cache_key": "basic_functions:22",
        "timeout": 6000,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "6ae6968aa09614ac4c4a3158322b0c5742fe5f59111d6532bf3f483d97ab9ffd"
    },
    "basic_functions.BasicFunctions.peakmem_write_staged": {
        "code": "class BasicFunctions:\n    def peakmem_write_staged(self, rows, num_symbols):\n        lib = self.get_fresh_lib()\n        for sym in range(num_symbols):\n            lib.write(f\"{sym}_sym\", self.df, staged=True)\n    \n        for sym in range(num_symbols):\n            lib._nvs.compact_incomplete(f\"{sym}_sym\", False, False)\n\n    def setup(self, rows, num_symbols):\n        self.ac = Arctic(\"lmdb://basic_functions\")\n        self.read_reqs = [ReadRequest(f\"{sym}_sym\") for sym in range(num_symbols)]\n    \n        self.df = generate_pseudo_random_dataframe(rows)\n        self.df_short_wide = generate_random_floats_dataframe(5_000, 30_000)\n\n    def setup_cache(self):\n        self.ac = Arctic(\"lmdb://basic_functions\")\n        num_rows, num_symbols = BasicFunctions.params\n    \n        self.dfs = {rows: generate_pseudo_random_dataframe(rows) for rows in num_rows}\n        for rows in num_rows:\n            lib = get_prewritten_lib_name(rows)\n            self.ac.delete_library(lib)\n            self.ac.create_library(lib)\n            lib = self.ac[lib]\n            for sym in range(num_symbols[-1]):\n                lib.write(f\"{sym}_sym\", self.dfs[rows])\n        for sym in range(num_symbols[-1]):\n            lib.write(f\"{sym}_short_wide_sym\", generate_random_floats_dataframe(5_000, 30_000))",
        "name": "basic_functions.BasicFunctions.peakmem_write_staged",
        "param_names": [
            "rows",
            "num_symbols"
        ],
        "params": [
            [
                "100000",
                "150000"
            ],
            [
                "500",
                "1000"
            ]
        ],
        "setup_cache_key": "basic_functions:22",
        "timeout": 6000,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "0a5ad0cf1a9e534ebabf7587d980d299d6d0a4a1e7a202be776871c782cfde08"
    },
    "basic_functions.BasicFunctions.time_read": {
        "code": "class BasicFunctions:\n    def time_read(self, rows, num_symbols):\n        lib = self.ac[get_prewritten_lib_name(rows)]\n        [lib.read(f\"{sym}_sym\").data for sym in range(num_symbols)]\n\n    def setup(self, rows, num_symbols):\n        self.ac = Arctic(\"lmdb://basic_functions\")\n        self.read_reqs = [ReadRequest(f\"{sym}_sym\") for sym in range(num_symbols)]\n    \n        self.df = generate_pseudo_random_dataframe(rows)\n        self.df_short_wide = generate_random_floats_dataframe(5_000, 30_000)\n\n    def setup_cache(self):\n        self.ac = Arctic(\"lmdb://basic_functions\")\n        num_rows, num_symbols = BasicFunctions.params\n    \n        self.dfs = {rows: generate_pseudo_random_dataframe(rows) for rows in num_rows}\n        for rows in num_rows:\n            lib = get_prewritten_lib_name(rows)\n            self.ac.delete_library(lib)\n            self.ac.create_library(lib)\n            lib = self.ac[lib]\n            for sym in range(num_symbols[-1]):\n                lib.write(f\"{sym}_sym\", self.dfs[rows])\n        for sym in range(num_symbols[-1]):\n            lib.write(f\"{sym}_short_wide_sym\", generate_random_floats_dataframe(5_000, 30_000))",
        "min_run_count": 2,
        "name": "basic_functions.BasicFunctions.time_read",
        "number": 5,
        "param_names": [
            "rows",
            "num_symbols"
        ],
        "params": [
            [
                "100000",
                "150000"
            ],
            [
                "500",
                "1000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "basic_functions:22",
        "timeout": 6000,
        "type": "time",
        "unit": "seconds",
        "version": "af8e6c31f8a69a1ab2b9b163b682d591b4067f257874d193e4f1d9184cefe437",
        "warmup_time": -1
    },
    "basic_functions.BasicFunctions.time_read_batch": {
        "code": "class BasicFunctions:\n    def time_read_batch(self, rows, num_symbols):\n        lib = self.ac[get_prewritten_lib_name(rows)]\n        read_reqs = [ReadRequest(f\"{sym}_sym\") for sym in range(num_symbols)]\n        lib.read_batch(read_reqs)\n\n    def setup(self, rows, num_symbols):\n        self.ac = Arctic(\"lmdb://basic_functions\")\n        self.read_reqs = [ReadRequest(f\"{sym}_sym\") for sym in range(num_symbols)]\n    \n        self.df = generate_pseudo_random_dataframe(rows)\n        self.df_short_wide = generate_random_floats_dataframe(5_000, 30_000)\n\n    def setup_cache(self):\n        self.ac = Arctic(\"lmdb://basic_functions\")\n        num_rows, num_symbols = BasicFunctions.params\n    \n        self.dfs = {rows: generate_pseudo_random_dataframe(rows) for rows in num_rows}\n        for rows in num_rows:\n            lib = get_prewritten_lib_name(rows)\n            self.ac.delete_library(lib)\n            self.ac.create_library(lib)\n            lib = self.ac[lib]\n            for sym in range(num_symbols[-1]):\n                lib.write(f\"{sym}_sym\", self.dfs[rows])\n        for sym in range(num_symbols[-1]):\n            lib.write(f\"{sym}_short_wide_sym\", generate_random_floats_dataframe(5_000, 30_000))",
        "min_run_count": 2,
        "name": "basic_functions.BasicFunctions.time_read_batch",
        "number": 5,
        "param_names": [
            "rows",
            "num_symbols"
        ],
        "params": [
            [
                "100000",
                "150000"
            ],
            [
                "500",
                "1000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "basic_functions:22",
        "timeout": 6000,
        "type": "time",
        "unit": "seconds",
        "version": "82da2291bc3ff8a193968b03e72a8f72d77e4fdf0c4ac636ef4433fcf706c229",
        "warmup_time": -1
    },
    "basic_functions.BasicFunctions.time_read_batch_pure": {
        "code": "class BasicFunctions:\n    def time_read_batch_pure(self, rows, num_symbols):\n        lib = self.ac[get_prewritten_lib_name(rows)]\n        lib.read_batch(self.read_reqs)\n\n    def setup(self, rows, num_symbols):\n        self.ac = Arctic(\"lmdb://basic_functions\")\n        self.read_reqs = [ReadRequest(f\"{sym}_sym\") for sym in range(num_symbols)]\n    \n        self.df = generate_pseudo_random_dataframe(rows)\n        self.df_short_wide = generate_random_floats_dataframe(5_000, 30_000)\n\n    def setup_cache(self):\n        self.ac = Arctic(\"lmdb://basic_functions\")\n        num_rows, num_symbols = BasicFunctions.params\n    \n        self.dfs = {rows: generate_pseudo_random_dataframe(rows) for rows in num_rows}\n        for rows in num_rows:\n            lib = get_prewritten_lib_name(rows)\n            self.ac.delete_library(lib)\n            self.ac.create_library(lib)\n            lib = self.ac[lib]\n            for sym in range(num_symbols[-1]):\n                lib.write(f\"{sym}_sym\", self.dfs[rows])\n        for sym in range(num_symbols[-1]):\n            lib.write(f\"{sym}_short_wide_sym\", generate_random_floats_dataframe(5_000, 30_000))",
        "min_run_count": 2,
        "name": "basic_functions.BasicFunctions.time_read_batch_pure",
        "number": 5,
        "param_names": [
            "rows",
            "num_symbols"
        ],
        "params": [
            [
                "100000",
                "150000"
            ],
            [
                "500",
                "1000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "basic_functions:22",
        "timeout": 6000,
        "type": "time",
        "unit": "seconds",
        "version": "e6d2eab059deb5e420003e25514187d81253dc7c83b584ab5c47e80e56be7ca2",
        "warmup_time": -1
    },
    "basic_functions.BasicFunctions.time_read_batch_with_columns": {
        "code": "class BasicFunctions:\n    def time_read_batch_with_columns(self, rows, num_symbols):\n        lib = self.ac[get_prewritten_lib_name(rows)]\n        COLS = [\"value\"]\n        read_reqs = [ReadRequest(f\"{sym}_sym\", columns=COLS) for sym in range(num_symbols)]\n        lib.read_batch(read_reqs)\n\n    def setup(self, rows, num_symbols):\n        self.ac = Arctic(\"lmdb://basic_functions\")\n        self.read_reqs = [ReadRequest(f\"{sym}_sym\") for sym in range(num_symbols)]\n    \n        self.df = generate_pseudo_random_dataframe(rows)\n        self.df_short_wide = generate_random_floats_dataframe(5_000, 30_000)\n\n    def setup_cache(self):\n        self.ac = Arctic(\"lmdb://basic_functions\")\n        num_rows, num_symbols = BasicFunctions.params\n    \n        self.dfs = {rows: generate_pseudo_random_dataframe(rows) for rows in num_rows}\n        for rows in num_rows:\n            lib = get_prewritten_lib_name(rows)\n            self.ac.delete_library(lib)\n            self.ac.create_library(lib)\n            lib = self.ac[lib]\n            for sym in range(num_symbols[-1]):\n                lib.write(f\"{sym}_sym\", self.dfs[rows])\n        for sym in range(num_symbols[-1]):\n            lib.write(f\"{sym}_short_wide_sym\", generate_random_floats_dataframe(5_000, 30_000))",
        "min_run_count": 2,
        "name": "basic_functions.BasicFunctions.time_read_batch_with_columns",
        "number": 5,
        "param_names": [
            "rows",
            "num_symbols"
        ],
        "params": [
            [
                "100000",
                "150000"
            ],
            [
                "500",
                "1000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "basic_functions:22",
        "timeout": 6000,
        "type": "time",
        "unit": "seconds",
        "version": "d8eaa6d8d605f1c6fe9bc3ca7ca819e89d1dac0bd7a75a781483ea689550a0c0",
        "warmup_time": -1
    },
    "basic_functions.BasicFunctions.time_read_batch_with_date_ranges": {
        "code": "class BasicFunctions:\n    def time_read_batch_with_date_ranges(self, rows, num_symbols):\n        lib = self.ac[get_prewritten_lib_name(rows)]\n        dr = pd.date_range(\"2023-01-01\", \"2023-01-01\")\n        read_reqs = [ReadRequest(f\"{sym}_sym\", date_range=dr) for sym in range(num_symbols)]\n        lib.read_batch(read_reqs)\n\n    def setup(self, rows, num_symbols):\n        self.ac = Arctic(\"lmdb://basic_functions\")\n        self.read_reqs = [ReadRequest(f\"{sym}_sym\") for sym in range(num_symbols)]\n    \n        self.df = generate_pseudo_random_dataframe(rows)\n        self.df_short_wide = generate_random_floats_dataframe(5_000, 30_000)\n\n    def setup_cache(self):\n        self.ac = Arctic(\"lmdb://basic_functions\")\n        num_rows, num_symbols = BasicFunctions.params\n    \n        self.dfs = {rows: generate_pseudo_random_dataframe(rows) for rows in num_rows}\n        for rows in num_rows:\n            lib = get_prewritten_lib_name(rows)\n            self.ac.delete_library(lib)\n            self.ac.create_library(lib)\n            lib = self.ac[lib]\n            for sym in range(num_symbols[-1]):\n                lib.write(f\"{sym}_sym\", self.dfs[rows])\n        for sym in range(num_symbols[-1]):\n            lib.write(f\"{sym}_short_wide_sym\", generate_random_floats_dataframe(5_000, 30_000))",
        "min_run_count": 2,
        "name": "basic_functions.BasicFunctions.time_read_batch_with_date_ranges",
        "number": 5,
        "param_names": [
            "rows",
            "num_symbols"
        ],
        "params": [
            [
                "100000",
                "150000"
            ],
            [
                "500",
                "1000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "basic_functions:22",
        "timeout": 6000,
        "type": "time",
        "unit": "seconds",
        "version": "c23053b2a2a19161d8cef17ac239bfef3b2e5c71eb7d13505d8a02db2d28c485",
        "warmup_time": -1
    },
    "basic_functions.BasicFunctions.time_read_short_wide": {
        "code": "class BasicFunctions:\n    def time_read_short_wide(self, rows, num_symbols):\n        lib = self.ac[get_prewritten_lib_name(rows)]\n        [lib.read(f\"{sym}_short_wide_sym\").data for sym in range(num_symbols)]\n\n    def setup(self, rows, num_symbols):\n        self.ac = Arctic(\"lmdb://basic_functions\")\n        self.read_reqs = [ReadRequest(f\"{sym}_sym\") for sym in range(num_symbols)]\n    \n        self.df = generate_pseudo_random_dataframe(rows)\n        self.df_short_wide = generate_random_floats_dataframe(5_000, 30_000)\n\n    def setup_cache(self):\n        self.ac = Arctic(\"lmdb://basic_functions\")\n        num_rows, num_symbols = BasicFunctions.params\n    \n        self.dfs = {rows: generate_pseudo_random_dataframe(rows) for rows in num_rows}\n        for rows in num_rows:\n            lib = get_prewritten_lib_name(rows)\n            self.ac.delete_library(lib)\n            self.ac.create_library(lib)\n            lib = self.ac[lib]\n            for sym in range(num_symbols[-1]):\n                lib.write(f\"{sym}_sym\", self.dfs[rows])\n        for sym in range(num_symbols[-1]):\n            lib.write(f\"{sym}_short_wide_sym\", generate_random_floats_dataframe(5_000, 30_000))",
        "min_run_count": 2,
        "name": "basic_functions.BasicFunctions.time_read_short_wide",
        "number": 5,
        "param_names": [
            "rows",
            "num_symbols"
        ],
        "params": [
            [
                "100000",
                "150000"
            ],
            [
                "500",
                "1000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "basic_functions:22",
        "timeout": 6000,
        "type": "time",
        "unit": "seconds",
        "version": "d88a089e1683b6da3d3729ff3e820fcb2547aa5f0208c1627ff5ad9ebbefb08d",
        "warmup_time": -1
    },
    "basic_functions.BasicFunctions.time_read_with_columns": {
        "code": "class BasicFunctions:\n    def time_read_with_columns(self, rows, num_symbols):\n        lib = self.ac[get_prewritten_lib_name(rows)]\n        COLS = [\"value\"]\n        [lib.read(f\"{sym}_sym\", columns=COLS).data for sym in range(num_symbols)]\n\n    def setup(self, rows, num_symbols):\n        self.ac = Arctic(\"lmdb://basic_functions\")\n        self.read_reqs = [ReadRequest(f\"{sym}_sym\") for sym in range(num_symbols)]\n    \n        self.df = generate_pseudo_random_dataframe(rows)\n        self.df_short_wide = generate_random_floats_dataframe(5_000, 30_000)\n\n    def setup_cache(self):\n        self.ac = Arctic(\"lmdb://basic_functions\")\n        num_rows, num_symbols = BasicFunctions.params\n    \n        self.dfs = {rows: generate_pseudo_random_dataframe(rows) for rows in num_rows}\n        for rows in num_rows:\n            lib = get_prewritten_lib_name(rows)\n            self.ac.delete_library(lib)\n            self.ac.create_library(lib)\n            lib = self.ac[lib]\n            for sym in range(num_symbols[-1]):\n                lib.write(f\"{sym}_sym\", self.dfs[rows])\n        for sym in range(num_symbols[-1]):\n            lib.write(f\"{sym}_short_wide_sym\", generate_random_floats_dataframe(5_000, 30_000))",
        "min_run_count": 2,
        "name": "basic_functions.BasicFunctions.time_read_with_columns",
        "number": 5,
        "param_names": [
            "rows",
            "num_symbols"
        ],
        "params": [
            [
                "100000",
                "150000"
            ],
            [
                "500",
                "1000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "basic_functions:22",
        "timeout": 6000,
        "type": "time",
        "unit": "seconds",
        "version": "b918829b859ad717bd13c918b60bfcbb830f03115094df65030ed2469182b539",
        "warmup_time": -1
    },
    "basic_functions.BasicFunctions.time_read_with_date_ranges": {
        "code": "class BasicFunctions:\n    def time_read_with_date_ranges(self, rows, num_symbols):\n        lib = self.ac[get_prewritten_lib_name(rows)]\n        dr = pd.date_range(\"2023-01-01\", \"2023-01-01\")\n        [lib.read(f\"{sym}_sym\", date_range=dr).data for sym in range(num_symbols)]\n\n    def setup(self, rows, num_symbols):\n        self.ac = Arctic(\"lmdb://basic_functions\")\n        self.read_reqs = [ReadRequest(f\"{sym}_sym\") for sym in range(num_symbols)]\n    \n        self.df = generate_pseudo_random_dataframe(rows)\n        self.df_short_wide = generate_random_floats_dataframe(5_000, 30_000)\n\n    def setup_cache(self):\n        self.ac = Arctic(\"lmdb://basic_functions\")\n        num_rows, num_symbols = BasicFunctions.params\n    \n        self.dfs = {rows: generate_pseudo_random_dataframe(rows) for rows in num_rows}\n        for rows in num_rows:\n            lib = get_prewritten_lib_name(rows)\n            self.ac.delete_library(lib)\n            self.ac.create_library(lib)\n            lib = self.ac[lib]\n            for sym in range(num_symbols[-1]):\n                lib.write(f\"{sym}_sym\", self.dfs[rows])\n        for sym in range(num_symbols[-1]):\n            lib.write(f\"{sym}_short_wide_sym\", generate_random_floats_dataframe(5_000, 30_000))",
        "min_run_count": 2,
        "name": "basic_functions.BasicFunctions.time_read_with_date_ranges",
        "number": 5,
        "param_names": [
            "rows",
            "num_symbols"
        ],
        "params": [
            [
                "100000",
                "150000"
            ],
            [
                "500",
                "1000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "basic_functions:22",
        "timeout": 6000,
        "type": "time",
        "unit": "seconds",
        "version": "0ed8c820b6f4c882ebda3d408e2645bbad1679bce0e3a8aad362e3823a53377b",
        "warmup_time": -1
    },
    "basic_functions.BasicFunctions.time_write": {
        "code": "class BasicFunctions:\n    def time_write(self, rows, num_symbols):\n        lib = self.get_fresh_lib()\n        for sym in range(num_symbols):\n            lib.write(f\"{sym}_sym\", self.df)\n\n    def setup(self, rows, num_symbols):\n        self.ac = Arctic(\"lmdb://basic_functions\")\n        self.read_reqs = [ReadRequest(f\"{sym}_sym\") for sym in range(num_symbols)]\n    \n        self.df = generate_pseudo_random_dataframe(rows)\n        self.df_short_wide = generate_random_floats_dataframe(5_000, 30_000)\n\n    def setup_cache(self):\n        self.ac = Arctic(\"lmdb://basic_functions\")\n        num_rows, num_symbols = BasicFunctions.params\n    \n        self.dfs = {rows: generate_pseudo_random_dataframe(rows) for rows in num_rows}\n        for rows in num_rows:\n            lib = get_prewritten_lib_name(rows)\n            self.ac.delete_library(lib)\n            self.ac.create_library(lib)\n            lib = self.ac[lib]\n            for sym in range(num_symbols[-1]):\n                lib.write(f\"{sym}_sym\", self.dfs[rows])\n        for sym in range(num_symbols[-1]):\n            lib.write(f\"{sym}_short_wide_sym\", generate_random_floats_dataframe(5_000, 30_000))",
        "min_run_count": 2,
        "name": "basic_functions.BasicFunctions.time_write",
        "number": 5,
        "param_names": [
            "rows",
            "num_symbols"
        ],
        "params": [
            [
                "100000",
                "150000"
            ],
            [
                "500",
                "1000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "basic_functions:22",
        "timeout": 6000,
        "type": "time",
        "unit": "seconds",
        "version": "b47979b7d52e1edfa6ea78e9d3fe9355e9d5d01c4ac47623352ca9ba9a7faa5d",
        "warmup_time": -1
    },
    "basic_functions.BasicFunctions.time_write_batch": {
        "code": "class BasicFunctions:\n    def time_write_batch(self, rows, num_symbols):\n        lib = self.get_fresh_lib()\n        df = self.df\n        payloads = [WritePayload(f\"{sym}_sym\", df) for sym in range(num_symbols)]\n        lib.write_batch(payloads)\n\n    def setup(self, rows, num_symbols):\n        self.ac = Arctic(\"lmdb://basic_functions\")\n        self.read_reqs = [ReadRequest(f\"{sym}_sym\") for sym in range(num_symbols)]\n    \n        self.df = generate_pseudo_random_dataframe(rows)\n        self.df_short_wide = generate_random_floats_dataframe(5_000, 30_000)\n\n    def setup_cache(self):\n        self.ac = Arctic(\"lmdb://basic_functions\")\n        num_rows, num_symbols = BasicFunctions.params\n    \n        self.dfs = {rows: generate_pseudo_random_dataframe(rows) for rows in num_rows}\n        for rows in num_rows:\n            lib = get_prewritten_lib_name(rows)\n            self.ac.delete_library(lib)\n            self.ac.create_library(lib)\n            lib = self.ac[lib]\n            for sym in range(num_symbols[-1]):\n                lib.write(f\"{sym}_sym\", self.dfs[rows])\n        for sym in range(num_symbols[-1]):\n            lib.write(f\"{sym}_short_wide_sym\", generate_random_floats_dataframe(5_000, 30_000))",
        "min_run_count": 2,
        "name": "basic_functions.BasicFunctions.time_write_batch",
        "number": 5,
        "param_names": [
            "rows",
            "num_symbols"
        ],
        "params": [
            [
                "100000",
                "150000"
            ],
            [
                "500",
                "1000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "basic_functions:22",
        "timeout": 6000,
        "type": "time",
        "unit": "seconds",
        "version": "545a869dfcb3b34b03314391a1ebd35b737c54eec98211ea1eb0c92aa9979447",
        "warmup_time": -1
    },
    "basic_functions.BasicFunctions.time_write_short_wide": {
        "code": "class BasicFunctions:\n    def time_write_short_wide(self, rows, num_symbols):\n        lib = self.get_fresh_lib()\n        for sym in range(num_symbols):\n            lib.write(f\"{sym}_short_wide_sym\", self.df_short_wide)\n\n    def setup(self, rows, num_symbols):\n        self.ac = Arctic(\"lmdb://basic_functions\")\n        self.read_reqs = [ReadRequest(f\"{sym}_sym\") for sym in range(num_symbols)]\n    \n        self.df = generate_pseudo_random_dataframe(rows)\n        self.df_short_wide = generate_random_floats_dataframe(5_000, 30_000)\n\n    def setup_cache(self):\n        self.ac = Arctic(\"lmdb://basic_functions\")\n        num_rows, num_symbols = BasicFunctions.params\n    \n        self.dfs = {rows: generate_pseudo_random_dataframe(rows) for rows in num_rows}\n        for rows in num_rows:\n            lib = get_prewritten_lib_name(rows)\n            self.ac.delete_library(lib)\n            self.ac.create_library(lib)\n            lib = self.ac[lib]\n            for sym in range(num_symbols[-1]):\n                lib.write(f\"{sym}_sym\", self.dfs[rows])\n        for sym in range(num_symbols[-1]):\n            lib.write(f\"{sym}_short_wide_sym\", generate_random_floats_dataframe(5_000, 30_000))",
        "min_run_count": 2,
        "name": "basic_functions.BasicFunctions.time_write_short_wide",
        "number": 5,
        "param_names": [
            "rows",
            "num_symbols"
        ],
        "params": [
            [
                "100000",
                "150000"
            ],
            [
                "500",
                "1000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "basic_functions:22",
        "timeout": 6000,
        "type": "time",
        "unit": "seconds",
        "version": "b1bef3cfec238dbf9d96ca87c04cba1d2637e84a1f6cd32aec2089d614641cab",
        "warmup_time": -1
    },
    "basic_functions.BasicFunctions.time_write_staged": {
        "code": "class BasicFunctions:\n    def time_write_staged(self, rows, num_symbols):\n        lib = self.get_fresh_lib()\n        for sym in range(num_symbols):\n            lib.write(f\"{sym}_sym\", self.df, staged=True)\n    \n        for sym in range(num_symbols):\n            lib._nvs.compact_incomplete(f\"{sym}_sym\", False, False)\n\n    def setup(self, rows, num_symbols):\n        self.ac = Arctic(\"lmdb://basic_functions\")\n        self.read_reqs = [ReadRequest(f\"{sym}_sym\") for sym in range(num_symbols)]\n    \n        self.df = generate_pseudo_random_dataframe(rows)\n        self.df_short_wide = generate_random_floats_dataframe(5_000, 30_000)\n\n    def setup_cache(self):\n        self.ac = Arctic(\"lmdb://basic_functions\")\n        num_rows, num_symbols = BasicFunctions.params\n    \n        self.dfs = {rows: generate_pseudo_random_dataframe(rows) for rows in num_rows}\n        for rows in num_rows:\n            lib = get_prewritten_lib_name(rows)\n            self.ac.delete_library(lib)\n            self.ac.create_library(lib)\n            lib = self.ac[lib]\n            for sym in range(num_symbols[-1]):\n                lib.write(f\"{sym}_sym\", self.dfs[rows])\n        for sym in range(num_symbols[-1]):\n            lib.write(f\"{sym}_short_wide_sym\", generate_random_floats_dataframe(5_000, 30_000))",
        "min_run_count": 2,
        "name": "basic_functions.BasicFunctions.time_write_staged",
        "number": 5,
        "param_names": [
            "rows",
            "num_symbols"
        ],
        "params": [
            [
                "100000",
                "150000"
            ],
            [
                "500",
                "1000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "basic_functions:22",
        "timeout": 6000,
        "type": "time",
        "unit": "seconds",
        "version": "07b7856529b455127827cbc9f05d83865edfabc954fdd9b35f002327c638f600",
        "warmup_time": -1
    },
    "list_functions.ListFunctions.peakmem_list_symbols": {
        "code": "class ListFunctions:\n    def peakmem_list_symbols(self, num_symbols):\n        lib = self.ac[f\"{num_symbols}_num_symbols\"]\n        lib.list_symbols()\n\n    def setup(self, num_symbols):\n        self.ac = Arctic(\"lmdb://list_functions\")\n\n    def setup_cache(self):\n        self.ac = Arctic(\"lmdb://list_functions\")\n    \n        num_symbols = ListFunctions.params\n        for syms in num_symbols:\n            lib_name = f\"{syms}_num_symbols\"\n            self.ac.delete_library(lib_name)\n            self.ac.create_library(lib_name)\n            lib = self.ac[lib_name]\n            for sym in range(syms):\n                lib.write(f\"{sym}_sym\", generate_benchmark_df(ListFunctions.rows))",
        "name": "list_functions.ListFunctions.peakmem_list_symbols",
        "param_names": [
            "num_symbols"
        ],
        "params": [
            [
                "500",
                "1000"
            ]
        ],
        "setup_cache_key": "list_functions:22",
        "timeout": 6000,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "0d50729844beae58e9cba083ee7214a55e5c1639b8439842ed1cdf080b7b2a4f"
    },
    "list_functions.ListFunctions.peakmem_list_versions": {
        "code": "class ListFunctions:\n    def peakmem_list_versions(self, num_symbols):\n        lib = self.ac[f\"{num_symbols}_num_symbols\"]\n        lib.list_versions()\n\n    def setup(self, num_symbols):\n        self.ac = Arctic(\"lmdb://list_functions\")\n\n    def setup_cache(self):\n        self.ac = Arctic(\"lmdb://list_functions\")\n    \n        num_symbols = ListFunctions.params\n        for syms in num_symbols:\n            lib_name = f\"{syms}_num_symbols\"\n            self.ac.delete_library(lib_name)\n            self.ac.create_library(lib_name)\n            lib = self.ac[lib_name]\n            for sym in range(syms):\n                lib.write(f\"{sym}_sym\", generate_benchmark_df(ListFunctions.rows))",
        "name": "list_functions.ListFunctions.peakmem_list_versions",
        "param_names": [
            "num_symbols"
        ],
        "params": [
            [
                "500",
                "1000"
            ]
        ],
        "setup_cache_key": "list_functions:22",
        "timeout": 6000,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "c317f2aa935e2b739a1a232439412ad1da88ee9eb332daf0f560e00ec27f1143"
    },
    "list_functions.ListFunctions.time_has_symbol": {
        "code": "class ListFunctions:\n    def time_has_symbol(self, num_symbols):\n        lib = self.ac[f\"{num_symbols}_num_symbols\"]\n        lib.has_symbol(\"250_sym\")\n\n    def setup(self, num_symbols):\n        self.ac = Arctic(\"lmdb://list_functions\")\n\n    def setup_cache(self):\n        self.ac = Arctic(\"lmdb://list_functions\")\n    \n        num_symbols = ListFunctions.params\n        for syms in num_symbols:\n            lib_name = f\"{syms}_num_symbols\"\n            self.ac.delete_library(lib_name)\n            self.ac.create_library(lib_name)\n            lib = self.ac[lib_name]\n            for sym in range(syms):\n                lib.write(f\"{sym}_sym\", generate_benchmark_df(ListFunctions.rows))",
        "min_run_count": 2,
        "name": "list_functions.ListFunctions.time_has_symbol",
        "number": 5,
        "param_names": [
            "num_symbols"
        ],
        "params": [
            [
                "500",
                "1000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "list_functions:22",
        "timeout": 6000,
        "type": "time",
        "unit": "seconds",
        "version": "8a8e9e8927b3b8698d1ef4bab4119455588fc62a3bbfa62321e6ce83f5f428ad",
        "warmup_time": -1
    },
    "list_functions.ListFunctions.time_list_symbols": {
        "code": "class ListFunctions:\n    def time_list_symbols(self, num_symbols):\n        lib = self.ac[f\"{num_symbols}_num_symbols\"]\n        lib.list_symbols()\n\n    def setup(self, num_symbols):\n        self.ac = Arctic(\"lmdb://list_functions\")\n\n    def setup_cache(self):\n        self.ac = Arctic(\"lmdb://list_functions\")\n    \n        num_symbols = ListFunctions.params\n        for syms in num_symbols:\n            lib_name = f\"{syms}_num_symbols\"\n            self.ac.delete_library(lib_name)\n            self.ac.create_library(lib_name)\n            lib = self.ac[lib_name]\n            for sym in range(syms):\n                lib.write(f\"{sym}_sym\", generate_benchmark_df(ListFunctions.rows))",
        "min_run_count": 2,
        "name": "list_functions.ListFunctions.time_list_symbols",
        "number": 5,
        "param_names": [
            "num_symbols"
        ],
        "params": [
            [
                "500",
                "1000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "list_functions:22",
        "timeout": 6000,
        "type": "time",
        "unit": "seconds",
        "version": "c91930aa368c8d3ad7bd56d7f827edcca3f16645c205bf6e042c57a5792a7113",
        "warmup_time": -1
    },
    "list_functions.ListFunctions.time_list_versions": {
        "code": "class ListFunctions:\n    def time_list_versions(self, num_symbols):\n        lib = self.ac[f\"{num_symbols}_num_symbols\"]\n        lib.list_versions()\n\n    def setup(self, num_symbols):\n        self.ac = Arctic(\"lmdb://list_functions\")\n\n    def setup_cache(self):\n        self.ac = Arctic(\"lmdb://list_functions\")\n    \n        num_symbols = ListFunctions.params\n        for syms in num_symbols:\n            lib_name = f\"{syms}_num_symbols\"\n            self.ac.delete_library(lib_name)\n            self.ac.create_library(lib_name)\n            lib = self.ac[lib_name]\n            for sym in range(syms):\n                lib.write(f\"{sym}_sym\", generate_benchmark_df(ListFunctions.rows))",
        "min_run_count": 2,
        "name": "list_functions.ListFunctions.time_list_versions",
        "number": 5,
        "param_names": [
            "num_symbols"
        ],
        "params": [
            [
                "500",
                "1000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "list_functions:22",
        "timeout": 6000,
        "type": "time",
        "unit": "seconds",
        "version": "ed4587ca351d24477560baa8e184e265b612140183e88c412c36bf8a9352191c",
        "warmup_time": -1
    },
    "local_query_builder.LocalQueryBuilderFunctions.peakmem_filtering_numeric": {
        "code": "class LocalQueryBuilderFunctions:\n    def peakmem_filtering_numeric(self, num_rows):\n        lib = self.ac[self.lib_name]\n        q = QueryBuilder()\n        # v3 is random floats between 0 and 100\n        q = q[q[\"v3\"] < 10.0]\n        lib.read(f\"{num_rows}_rows\", columns=[\"v3\"], query_builder=q)\n\n    def setup(self, num_rows):\n        self.ac = Arctic(\"lmdb://query_builder?map_size=5GB\")\n        self.lib_name = \"query_builder\"\n\n    def setup_cache(self):\n        self.ac = Arctic(\"lmdb://query_builder?map_size=5GB\")\n    \n        num_rows = LocalQueryBuilderFunctions.params\n        self.lib_name = \"query_builder\"\n        self.ac.delete_library(self.lib_name)\n        self.ac.create_library(self.lib_name)\n        lib = self.ac[self.lib_name]\n        for rows in num_rows:\n            lib.write(f\"{rows}_rows\", generate_benchmark_df(rows))",
        "name": "local_query_builder.LocalQueryBuilderFunctions.peakmem_filtering_numeric",
        "param_names": [
            "num_rows"
        ],
        "params": [
            [
                "1000000",
                "10000000"
            ]
        ],
        "setup_cache_key": "local_query_builder:21",
        "timeout": 6000,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "119932c4738eb092fbbd9da22b3ff1e16bd4d6052dace2da6748fff5b416462d"
    },
    "local_query_builder.LocalQueryBuilderFunctions.peakmem_filtering_string_isin": {
        "code": "class LocalQueryBuilderFunctions:\n    def peakmem_filtering_string_isin(self, num_rows):\n        lib = self.ac[self.lib_name]\n        # Selects about 1% of the rows\n        k = num_rows // 1000\n        string_set = [f\"id{str(i).zfill(3)}\" for i in range(1, k + 1)]\n        q = QueryBuilder()\n        q = q[q[\"id1\"].isin(string_set)]\n        lib.read(f\"{num_rows}_rows\", columns=[\"v3\"], query_builder=q)\n\n    def setup(self, num_rows):\n        self.ac = Arctic(\"lmdb://query_builder?map_size=5GB\")\n        self.lib_name = \"query_builder\"\n\n    def setup_cache(self):\n        self.ac = Arctic(\"lmdb://query_builder?map_size=5GB\")\n    \n        num_rows = LocalQueryBuilderFunctions.params\n        self.lib_name = \"query_builder\"\n        self.ac.delete_library(self.lib_name)\n        self.ac.create_library(self.lib_name)\n        lib = self.ac[self.lib_name]\n        for rows in num_rows:\n            lib.write(f\"{rows}_rows\", generate_benchmark_df(rows))",
        "name": "local_query_builder.LocalQueryBuilderFunctions.peakmem_filtering_string_isin",
        "param_names": [
            "num_rows"
        ],
        "params": [
            [
                "1000000",
                "10000000"
            ]
        ],
        "setup_cache_key": "local_query_builder:21",
        "timeout": 6000,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "e77e28f6a2cb96e5b549ca58b551462e0ff90d7704ad3cf12f3e2ad71b1ccd73"
    },
    "local_query_builder.LocalQueryBuilderFunctions.peakmem_projection": {
        "code": "class LocalQueryBuilderFunctions:\n    def peakmem_projection(self, num_rows):\n        lib = self.ac[self.lib_name]\n        q = QueryBuilder()\n        q = q.apply(\"new_col\", q[\"v2\"] * q[\"v3\"])\n        lib.read(f\"{num_rows}_rows\", columns=[\"new_col\"], query_builder=q)\n\n    def setup(self, num_rows):\n        self.ac = Arctic(\"lmdb://query_builder?map_size=5GB\")\n        self.lib_name = \"query_builder\"\n\n    def setup_cache(self):\n        self.ac = Arctic(\"lmdb://query_builder?map_size=5GB\")\n    \n        num_rows = LocalQueryBuilderFunctions.params\n        self.lib_name = \"query_builder\"\n        self.ac.delete_library(self.lib_name)\n        self.ac.create_library(self.lib_name)\n        lib = self.ac[self.lib_name]\n        for rows in num_rows:\n            lib.write(f\"{rows}_rows\", generate_benchmark_df(rows))",
        "name": "local_query_builder.LocalQueryBuilderFunctions.peakmem_projection",
        "param_names": [
            "num_rows"
        ],
        "params": [
            [
                "1000000",
                "10000000"
            ]
        ],
        "setup_cache_key": "local_query_builder:21",
        "timeout": 6000,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "928c58e85b09b5969e7b2302b3a3a3c5af5d47ce5bd1cd5245387bf34fcb266b"
    },
    "local_query_builder.LocalQueryBuilderFunctions.peakmem_query_1": {
        "code": "class LocalQueryBuilderFunctions:\n    def peakmem_query_1(self, num_rows):\n        lib = self.ac[self.lib_name]\n        q = QueryBuilder()\n        q = q.groupby(\"id1\").agg({\"v1\": \"sum\"})\n        lib.read(f\"{num_rows}_rows\", query_builder=q)\n\n    def setup(self, num_rows):\n        self.ac = Arctic(\"lmdb://query_builder?map_size=5GB\")\n        self.lib_name = \"query_builder\"\n\n    def setup_cache(self):\n        self.ac = Arctic(\"lmdb://query_builder?map_size=5GB\")\n    \n        num_rows = LocalQueryBuilderFunctions.params\n        self.lib_name = \"query_builder\"\n        self.ac.delete_library(self.lib_name)\n        self.ac.create_library(self.lib_name)\n        lib = self.ac[self.lib_name]\n        for rows in num_rows:\n            lib.write(f\"{rows}_rows\", generate_benchmark_df(rows))",
        "name": "local_query_builder.LocalQueryBuilderFunctions.peakmem_query_1",
        "param_names": [
            "num_rows"
        ],
        "params": [
            [
                "1000000",
                "10000000"
            ]
        ],
        "setup_cache_key": "local_query_builder:21",
        "timeout": 6000,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "a1d501b169474fd16fdb1e90760157944483bba8d81eb3cb5791bbd487706ef6"
    },
    "local_query_builder.LocalQueryBuilderFunctions.peakmem_query_3": {
        "code": "class LocalQueryBuilderFunctions:\n    def peakmem_query_3(self, num_rows):\n        lib = self.ac[self.lib_name]\n        q = QueryBuilder()\n        q = q.groupby(\"id3\").agg({\"v1\": \"sum\", \"v3\": \"sum\"})\n        lib.read(f\"{num_rows}_rows\", query_builder=q)\n\n    def setup(self, num_rows):\n        self.ac = Arctic(\"lmdb://query_builder?map_size=5GB\")\n        self.lib_name = \"query_builder\"\n\n    def setup_cache(self):\n        self.ac = Arctic(\"lmdb://query_builder?map_size=5GB\")\n    \n        num_rows = LocalQueryBuilderFunctions.params\n        self.lib_name = \"query_builder\"\n        self.ac.delete_library(self.lib_name)\n        self.ac.create_library(self.lib_name)\n        lib = self.ac[self.lib_name]\n        for rows in num_rows:\n            lib.write(f\"{rows}_rows\", generate_benchmark_df(rows))",
        "name": "local_query_builder.LocalQueryBuilderFunctions.peakmem_query_3",
        "param_names": [
            "num_rows"
        ],
        "params": [
            [
                "1000000",
                "10000000"
            ]
        ],
        "setup_cache_key": "local_query_builder:21",
        "timeout": 6000,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "0b19c5c0e4be8742e99e32f13332544c343ac260474ee51bfb8911225c90b87b"
    },
    "local_query_builder.LocalQueryBuilderFunctions.peakmem_query_4": {
        "code": "class LocalQueryBuilderFunctions:\n    def peakmem_query_4(self, num_rows):\n        lib = self.ac[self.lib_name]\n        q = QueryBuilder()\n        q = q.groupby(\"id6\").agg({\"v1\": \"sum\", \"v2\": \"sum\"})\n        lib.read(f\"{num_rows}_rows\", query_builder=q)\n\n    def setup(self, num_rows):\n        self.ac = Arctic(\"lmdb://query_builder?map_size=5GB\")\n        self.lib_name = \"query_builder\"\n\n    def setup_cache(self):\n        self.ac = Arctic(\"lmdb://query_builder?map_size=5GB\")\n    \n        num_rows = LocalQueryBuilderFunctions.params\n        self.lib_name = \"query_builder\"\n        self.ac.delete_library(self.lib_name)\n        self.ac.create_library(self.lib_name)\n        lib = self.ac[self.lib_name]\n        for rows in num_rows:\n            lib.write(f\"{rows}_rows\", generate_benchmark_df(rows))",
        "name": "local_query_builder.LocalQueryBuilderFunctions.peakmem_query_4",
        "param_names": [
            "num_rows"
        ],
        "params": [
            [
                "1000000",
                "10000000"
            ]
        ],
        "setup_cache_key": "local_query_builder:21",
        "timeout": 6000,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "76d23e33cb5a319de6d0e007054bc0c3588cde135a08797e8f0c84493ed30189"
    },
    "local_query_builder.LocalQueryBuilderFunctions.peakmem_query_adv_query_2": {
        "code": "class LocalQueryBuilderFunctions:\n    def peakmem_query_adv_query_2(self, num_rows):\n        lib = self.ac[self.lib_name]\n        q = QueryBuilder()\n        q = q.groupby(\"id3\").agg({\"v1\": \"max\", \"v2\": \"min\"})\n        lib.read(f\"{num_rows}_rows\", query_builder=q)\n\n    def setup(self, num_rows):\n        self.ac = Arctic(\"lmdb://query_builder?map_size=5GB\")\n        self.lib_name = \"query_builder\"\n\n    def setup_cache(self):\n        self.ac = Arctic(\"lmdb://query_builder?map_size=5GB\")\n    \n        num_rows = LocalQueryBuilderFunctions.params\n        self.lib_name = \"query_builder\"\n        self.ac.delete_library(self.lib_name)\n        self.ac.create_library(self.lib_name)\n        lib = self.ac[self.lib_name]\n        for rows in num_rows:\n            lib.write(f\"{rows}_rows\", generate_benchmark_df(rows))",
        "name": "local_query_builder.LocalQueryBuilderFunctions.peakmem_query_adv_query_2",
        "param_names": [
            "num_rows"
        ],
        "params": [
            [
                "1000000",
                "10000000"
            ]
        ],
        "setup_cache_key": "local_query_builder:21",
        "timeout": 6000,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "36489c1cb0a3965ff6003b10a5f5cf2f2354a619346e53c488b2a3d1a07fd4c2"
    },
    "local_query_builder.LocalQueryBuilderFunctions.time_filtering_numeric": {
        "code": "class LocalQueryBuilderFunctions:\n    def time_filtering_numeric(self, num_rows):\n        lib = self.ac[self.lib_name]\n        q = QueryBuilder()\n        # v3 is random floats between 0 and 100\n        q = q[q[\"v3\"] < 1.0]\n        lib.read(f\"{num_rows}_rows\", columns=[\"v3\"], query_builder=q)\n\n    def setup(self, num_rows):\n        self.ac = Arctic(\"lmdb://query_builder?map_size=5GB\")\n        self.lib_name = \"query_builder\"\n\n    def setup_cache(self):\n        self.ac = Arctic(\"lmdb://query_builder?map_size=5GB\")\n    \n        num_rows = LocalQueryBuilderFunctions.params\n        self.lib_name = \"query_builder\"\n        self.ac.delete_library(self.lib_name)\n        self.ac.create_library(self.lib_name)\n        lib = self.ac[self.lib_name]\n        for rows in num_rows:\n            lib.write(f\"{rows}_rows\", generate_benchmark_df(rows))",
        "min_run_count": 2,
        "name": "local_query_builder.LocalQueryBuilderFunctions.time_filtering_numeric",
        "number": 5,
        "param_names": [
            "num_rows"
        ],
        "params": [
            [
                "1000000",
                "10000000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "local_query_builder:21",
        "timeout": 6000,
        "type": "time",
        "unit": "seconds",
        "version": "441c9db2c41da7c09c3f758c1cd0993dc5ea674f05d708e8997567826a961251",
        "warmup_time": -1
    },
    "local_query_builder.LocalQueryBuilderFunctions.time_filtering_string_isin": {
        "code": "class LocalQueryBuilderFunctions:\n    def time_filtering_string_isin(self, num_rows):\n        lib = self.ac[self.lib_name]\n        # Selects about 1% of the rows\n        k = num_rows // 1000\n        string_set = [f\"id{str(i).zfill(3)}\" for i in range(1, k + 1)]\n        q = QueryBuilder()\n        q = q[q[\"id1\"].isin(string_set)]\n        lib.read(f\"{num_rows}_rows\", columns=[\"v3\"], query_builder=q)\n\n    def setup(self, num_rows):\n        self.ac = Arctic(\"lmdb://query_builder?map_size=5GB\")\n        self.lib_name = \"query_builder\"\n\n    def setup_cache(self):\n        self.ac = Arctic(\"lmdb://query_builder?map_size=5GB\")\n    \n        num_rows = LocalQueryBuilderFunctions.params\n        self.lib_name = \"query_builder\"\n        self.ac.delete_library(self.lib_name)\n        self.ac.create_library(self.lib_name)\n        lib = self.ac[self.lib_name]\n        for rows in num_rows:\n            lib.write(f\"{rows}_rows\", generate_benchmark_df(rows))",
        "min_run_count": 2,
        "name": "local_query_builder.LocalQueryBuilderFunctions.time_filtering_string_isin",
        "number": 5,
        "param_names": [
            "num_rows"
        ],
        "params": [
            [
                "1000000",
                "10000000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "local_query_builder:21",
        "timeout": 6000,
        "type": "time",
        "unit": "seconds",
        "version": "f9d819943b527f80d002995694ba8cfc60f5ed75586144f6c4d1ba612a761294",
        "warmup_time": -1
    },
    "local_query_builder.LocalQueryBuilderFunctions.time_projection": {
        "code": "class LocalQueryBuilderFunctions:\n    def time_projection(self, num_rows):\n        lib = self.ac[self.lib_name]\n        q = QueryBuilder()\n        q = q.apply(\"new_col\", q[\"v2\"] * q[\"v3\"])\n        lib.read(f\"{num_rows}_rows\", columns=[\"new_col\"], query_builder=q)\n\n    def setup(self, num_rows):\n        self.ac = Arctic(\"lmdb://query_builder?map_size=5GB\")\n        self.lib_name = \"query_builder\"\n\n    def setup_cache(self):\n        self.ac = Arctic(\"lmdb://query_builder?map_size=5GB\")\n    \n        num_rows = LocalQueryBuilderFunctions.params\n        self.lib_name = \"query_builder\"\n        self.ac.delete_library(self.lib_name)\n        self.ac.create_library(self.lib_name)\n        lib = self.ac[self.lib_name]\n        for rows in num_rows:\n            lib.write(f\"{rows}_rows\", generate_benchmark_df(rows))",
        "min_run_count": 2,
        "name": "local_query_builder.LocalQueryBuilderFunctions.time_projection",
        "number": 5,
        "param_names": [
            "num_rows"
        ],
        "params": [
            [
                "1000000",
                "10000000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "local_query_builder:21",
        "timeout": 6000,
        "type": "time",
        "unit": "seconds",
        "version": "911828bde306e54bd165122188fb8acc406697e8cc94daa3e02596c1efc4530a",
        "warmup_time": -1
    },
    "local_query_builder.LocalQueryBuilderFunctions.time_query_1": {
        "code": "class LocalQueryBuilderFunctions:\n    def time_query_1(self, num_rows):\n        lib = self.ac[self.lib_name]\n        q = QueryBuilder()\n        q = q.groupby(\"id1\").agg({\"v1\": \"sum\"})\n        lib.read(f\"{num_rows}_rows\", query_builder=q)\n\n    def setup(self, num_rows):\n        self.ac = Arctic(\"lmdb://query_builder?map_size=5GB\")\n        self.lib_name = \"query_builder\"\n\n    def setup_cache(self):\n        self.ac = Arctic(\"lmdb://query_builder?map_size=5GB\")\n    \n        num_rows = LocalQueryBuilderFunctions.params\n        self.lib_name = \"query_builder\"\n        self.ac.delete_library(self.lib_name)\n        self.ac.create_library(self.lib_name)\n        lib = self.ac[self.lib_name]\n        for rows in num_rows:\n            lib.write(f\"{rows}_rows\", generate_benchmark_df(rows))",
        "min_run_count": 2,
        "name": "local_query_builder.LocalQueryBuilderFunctions.time_query_1",
        "number": 5,
        "param_names": [
            "num_rows"
        ],
        "params": [
            [
                "1000000",
                "10000000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "local_query_builder:21",
        "timeout": 6000,
        "type": "time",
        "unit": "seconds",
        "version": "e0d8b8b13b6012a8fe388a57e1d816fc387312c6595ff5cbf0490ae32a11642e",
        "warmup_time": -1
    },
    "local_query_builder.LocalQueryBuilderFunctions.time_query_3": {
        "code": "class LocalQueryBuilderFunctions:\n    def time_query_3(self, num_rows):\n        lib = self.ac[self.lib_name]\n        q = QueryBuilder()\n        q = q.groupby(\"id3\").agg({\"v1\": \"sum\", \"v3\": \"sum\"})\n        lib.read(f\"{num_rows}_rows\", query_builder=q)\n\n    def setup(self, num_rows):\n        self.ac = Arctic(\"lmdb://query_builder?map_size=5GB\")\n        self.lib_name = \"query_builder\"\n\n    def setup_cache(self):\n        self.ac = Arctic(\"lmdb://query_builder?map_size=5GB\")\n    \n        num_rows = LocalQueryBuilderFunctions.params\n        self.lib_name = \"query_builder\"\n        self.ac.delete_library(self.lib_name)\n        self.ac.create_library(self.lib_name)\n        lib = self.ac[self.lib_name]\n        for rows in num_rows:\n            lib.write(f\"{rows}_rows\", generate_benchmark_df(rows))",
        "min_run_count": 2,
        "name": "local_query_builder.LocalQueryBuilderFunctions.time_query_3",
        "number": 5,
        "param_names": [
            "num_rows"
        ],
        "params": [
            [
                "1000000",
                "10000000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "local_query_builder:21",
        "timeout": 6000,
        "type": "time",
        "unit": "seconds",
        "version": "22c320dbb7f3915712bffffef0c86ec9a51a167a8aee1af369ae9afceb47ad0b",
        "warmup_time": -1
    },
    "local_query_builder.LocalQueryBuilderFunctions.time_query_4": {
        "code": "class LocalQueryBuilderFunctions:\n    def time_query_4(self, num_rows):\n        lib = self.ac[self.lib_name]\n        q = QueryBuilder()\n        q = q.groupby(\"id6\").agg({\"v1\": \"sum\", \"v2\": \"sum\"})\n        lib.read(f\"{num_rows}_rows\", query_builder=q)\n\n    def setup(self, num_rows):\n        self.ac = Arctic(\"lmdb://query_builder?map_size=5GB\")\n        self.lib_name = \"query_builder\"\n\n    def setup_cache(self):\n        self.ac = Arctic(\"lmdb://query_builder?map_size=5GB\")\n    \n        num_rows = LocalQueryBuilderFunctions.params\n        self.lib_name = \"query_builder\"\n        self.ac.delete_library(self.lib_name)\n        self.ac.create_library(self.lib_name)\n        lib = self.ac[self.lib_name]\n        for rows in num_rows:\n            lib.write(f\"{rows}_rows\", generate_benchmark_df(rows))",
        "min_run_count": 2,
        "name": "local_query_builder.LocalQueryBuilderFunctions.time_query_4",
        "number": 5,
        "param_names": [
            "num_rows"
        ],
        "params": [
            [
                "1000000",
                "10000000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "local_query_builder:21",
        "timeout": 6000,
        "type": "time",
        "unit": "seconds",
        "version": "f6c81bfbe6bd6a3ed5de7ede40c048ee2e7f0f2f844608169ddf1768a18aa900",
        "warmup_time": -1
    },
    "local_query_builder.LocalQueryBuilderFunctions.time_query_adv_query_2": {
        "code": "class LocalQueryBuilderFunctions:\n    def time_query_adv_query_2(self, num_rows):\n        lib = self.ac[self.lib_name]\n        q = QueryBuilder()\n        q = q.groupby(\"id3\").agg({\"v1\": \"max\", \"v2\": \"min\"})\n        lib.read(f\"{num_rows}_rows\", query_builder=q)\n\n    def setup(self, num_rows):\n        self.ac = Arctic(\"lmdb://query_builder?map_size=5GB\")\n        self.lib_name = \"query_builder\"\n\n    def setup_cache(self):\n        self.ac = Arctic(\"lmdb://query_builder?map_size=5GB\")\n    \n        num_rows = LocalQueryBuilderFunctions.params\n        self.lib_name = \"query_builder\"\n        self.ac.delete_library(self.lib_name)\n        self.ac.create_library(self.lib_name)\n        lib = self.ac[self.lib_name]\n        for rows in num_rows:\n            lib.write(f\"{rows}_rows\", generate_benchmark_df(rows))",
        "min_run_count": 2,
        "name": "local_query_builder.LocalQueryBuilderFunctions.time_query_adv_query_2",
        "number": 5,
        "param_names": [
            "num_rows"
        ],
        "params": [
            [
                "1000000",
                "10000000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "local_query_builder:21",
        "timeout": 6000,
        "type": "time",
        "unit": "seconds",
        "version": "8167772e10cd53cd18fa670b57287145bdee6a010f1f8e07c9beec045706692e",
        "warmup_time": -1
    },
    "persistent_query_builder.PersistentQueryBuilderFunctions.time_query_1": {
        "code": "class PersistentQueryBuilderFunctions:\n    def time_query_1(self, num_rows):\n        lib = self.ac[self.lib_name]\n        q = QueryBuilder()\n        q = q.groupby(\"id1\").agg({\"v1\": \"sum\"})\n        lib.read(f\"{num_rows}_rows\", query_builder=q)\n\n    def setup(self, num_rows):\n        pass",
        "min_run_count": 2,
        "name": "persistent_query_builder.PersistentQueryBuilderFunctions.time_query_1",
        "number": 2,
        "param_names": [
            "param1"
        ],
        "params": [
            [
                "10000000",
                "100000000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 6000,
        "type": "time",
        "unit": "seconds",
        "version": "7edaf83428576cad92a57798d53958d802f264f8abcab93c1b449de09ab1ebbc",
        "warmup_time": -1
    },
    "persistent_query_builder.PersistentQueryBuilderFunctions.time_query_3": {
        "code": "class PersistentQueryBuilderFunctions:\n    def time_query_3(self, num_rows):\n        lib = self.ac[self.lib_name]\n        q = QueryBuilder()\n        q = q.groupby(\"id3\").agg({\"v1\": \"sum\", \"v3\": \"sum\"})\n        lib.read(f\"{num_rows}_rows\", query_builder=q)\n\n    def setup(self, num_rows):\n        pass",
        "min_run_count": 2,
        "name": "persistent_query_builder.PersistentQueryBuilderFunctions.time_query_3",
        "number": 2,
        "param_names": [
            "param1"
        ],
        "params": [
            [
                "10000000",
                "100000000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 6000,
        "type": "time",
        "unit": "seconds",
        "version": "44f3e60a071bbb6c7148d99bc2af9f7d56967c2c7f9cf0be63edb85395adbe53",
        "warmup_time": -1
    },
    "persistent_query_builder.PersistentQueryBuilderFunctions.time_query_4": {
        "code": "class PersistentQueryBuilderFunctions:\n    def time_query_4(self, num_rows):\n        lib = self.ac[self.lib_name]\n        q = QueryBuilder()\n        q = q.groupby(\"id6\").agg({\"v1\": \"sum\", \"v2\": \"sum\"})\n        lib.read(f\"{num_rows}_rows\", query_builder=q)\n\n    def setup(self, num_rows):\n        pass",
        "min_run_count": 2,
        "name": "persistent_query_builder.PersistentQueryBuilderFunctions.time_query_4",
        "number": 2,
        "param_names": [
            "param1"
        ],
        "params": [
            [
                "10000000",
                "100000000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 6000,
        "type": "time",
        "unit": "seconds",
        "version": "639820d89de31c1549b6d0a1f8f0944f901bcc7f6c540fa9650a2944b9e2fec5",
        "warmup_time": -1
    },
    "persistent_query_builder.PersistentQueryBuilderFunctions.time_query_adv_query_2": {
        "code": "class PersistentQueryBuilderFunctions:\n    def time_query_adv_query_2(self, num_rows):\n        lib = self.ac[self.lib_name]\n        q = QueryBuilder()\n        q = q.groupby(\"id3\").agg({\"v1\": \"max\", \"v2\": \"min\"})\n        lib.read(f\"{num_rows}_rows\", query_builder=q)\n\n    def setup(self, num_rows):\n        pass",
        "min_run_count": 2,
        "name": "persistent_query_builder.PersistentQueryBuilderFunctions.time_query_adv_query_2",
        "number": 2,
        "param_names": [
            "param1"
        ],
        "params": [
            [
                "10000000",
                "100000000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 6000,
        "type": "time",
        "unit": "seconds",
        "version": "af01c5b172dd634b9a9adfddf63bbbbdffe26b021bdf518273dddb325a382108",
        "warmup_time": -1
    },
    "version": 2
}